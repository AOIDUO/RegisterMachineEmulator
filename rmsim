#!/usr/bin/env python3

import argparse
import io
from lib2to3.pgen2.token import NEWLINE
import os
import sys
from numpy import identity

from pygments import lex

from frontend import Lexer, Parser, TokenKind
from emulator import Emulator
from typing import Callable, List

def pre_process(f):
    lines = f.readlines()
    stream = io.StringIO(''.join(lines))
    parser = Parser(Lexer(stream))
    
    if parser.check(TokenKind.IMPORT):
        alias_macro_map = {}
        
        # read all lines starting with "IMPORT"
        # and also read macros
        while parser.check(TokenKind.IMPORT):
            parser.match(TokenKind.IMPORT)
            dir = parser.match(TokenKind.DIRECTORY).value
            parser.match(TokenKind.AS)
            alias = parser.match(TokenKind.IDENTIFIER).value
            parser.match(TokenKind.NEWLINE)

            if not os.path.isabs(dir):
                dir = os.path.join(os.getcwd(), dir)
            x,_ = pre_process(open(dir,mode='r'))
            alias_macro_map[alias] = (dir,x)
        
        # chop off import haeding
        line_of_registers_symbol = parser.lexer.peek().line
        lines = lines[line_of_registers_symbol:]
        
        # replacement
        for i in range(len(lines)):
            lexer = Lexer(io.StringIO(lines[i]))
            token = lexer.consume()


            if lexer.peek().kind == TokenKind.COLON:
                token = lexer.consume()
                token = lexer.consume()

            if token.kind == TokenKind.IDENTIFIER and token.value in alias_macro_map:
                alias = token.value
                new_line = ''.join(alias_macro_map[alias][1])
                param_count = 0
                token = lexer.consume()
                while token.kind != TokenKind.NEWLINE:
                    if token.kind == TokenKind.REGISTER:
                        new_line = new_line.replace(f"${param_count}", f"r{token.value}")
                    else:
                        new_line = new_line.replace(f"${param_count}", token.value)
                    param_count += 1
                    token = lexer.consume()


                lines[i] = new_line + '\n'

        return lines, io.StringIO(''.join(lines))
    else: 
        return lines, io.StringIO(''.join(lines))



class RegMachineMain:
    args: argparse.Namespace

    def __init__(self, args: argparse.Namespace):
        self.args = args

    def parse(self):
        """Parse the input file."""
        if self.args.input_file is None:
            f = sys.stdin
        else:
            f = open(self.args.input_file, mode='r')

        _,f = pre_process(f)
        # pre-process: replace macro with actual instructions


        lexer = Lexer(f)
        parser = Parser(lexer)
        self.program = parser.parse_input()

    def emulate(self):
        e = Emulator(*self.program)
        e.run(trace=self.args.trace)

    def lexerdebug(self):
        """Parse the input file."""
        if self.args.input_file is None:
            f = sys.stdin
        else:
            f = open(self.args.input_file, mode='r')
        lexer = Lexer(f)
        token = lexer.consume()
        while token.kind != TokenKind.EOF:
            print(token)
            token = lexer.consume()
        print(token)

arg_parser = argparse.ArgumentParser(
    description='1')
arg_parser.add_argument("input_file", type=str, nargs="?", help="Path to input file")
arg_parser.add_argument("-t", "--trace", action='store_true')
# arg_parser.add_argument("-m", "--macro", nargs='+', default=[], help="macros")

def __main__(args: argparse.Namespace):
    regm_main = RegMachineMain(args)
    regm_main.parse()
    regm_main.emulate()
    # regm_main.lexerdebug()

    if args.trace:
        pass


if __name__ == "__main__":
    args = arg_parser.parse_args()
    __main__(args)
